{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import pdb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"resultsfinal\")\n",
    "os.makedirs(\"resultsfinal/predictions\")\n",
    "###### Load the data #########\n",
    "train = pd.read_csv(\"data/train_AIS.csv\");\n",
    "test = pd.read_csv(\"data/test_AIS.csv\");\n",
    "train_crbm = pd.read_csv(\"data/train_crbm_AIS.csv\");\n",
    "test_crbm = pd.read_csv(\"data/test_crbm_AIS.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### encoding class names as integers  from 0 to C-1 for C classes  #########\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train[\"type\"])\n",
    "train[\"type\"] = encoder.transform(train[\"type\"])\n",
    "test[\"type\"] = encoder.transform(test[\"type\"])\n",
    "train_crbm[\"type\"] = encoder.transform(train_crbm[\"type\"])\n",
    "test_crbm[\"type\"] = encoder.transform(test_crbm[\"type\"]);\n",
    "pd.DataFrame(encoder.classes_).to_csv(\"./resultsfinal/encoder_classes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define target name #########\n",
    "target = [\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define feature names #########\n",
    "features = [\"rotationGPS20\", \"bathymetry320\", \"sog20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hist = [\"rotationGPS\" + str(i) for i in range(1,21)] + \\\n",
    "                [\"sog\" + str(i) for i in range(1,21)] + \\\n",
    "                [\"bathymetry3\" + str(i) for i in range(1,21)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_crbm = ['activations.' + str(i) for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define train and test sets for the 3 experiments ######\n",
    "X_tr = np.array(train[features])\n",
    "y_tr = np.array(train[target[0]])\n",
    "X_tr = (X_tr - np.mean(X_tr, 0)) / np.std(X_tr, 0)\n",
    "X_te = np.array(test[features])\n",
    "y_te = np.array(test[target[0]])\n",
    "X_te = (X_te - np.mean(X_te, 0)) / np.std(X_te, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_hist = np.array(train[features_hist])\n",
    "y_tr = np.array(train[target[0]])\n",
    "X_tr_hist = (X_tr_hist - np.mean(X_tr_hist, 0)) / np.std(X_tr_hist, 0)\n",
    "X_te_hist = np.array(test[features_hist])\n",
    "y_te  = np.array(test[target[0]])\n",
    "X_te_hist = (X_te_hist - np.mean(X_te_hist, 0)) / np.std(X_te_hist, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_crbm = np.array(train_crbm[features_crbm])\n",
    "y_tr_crbm = np.array(train_crbm[target[0]])\n",
    "#X_tr_crbm = (X_tr_crbm - np.mean(X_tr_crbm, 0)) / np.std(X_tr_crbm, 0)\n",
    "X_te_crbm = np.array(test_crbm[features_crbm])\n",
    "y_te_crbm  = np.array(test_crbm[target[0]])\n",
    "#X_te_crbm = (X_te_crbm - np.mean(X_te_crbm, 0)) / np.std(X_te_crbm, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc = {\"original_features\":{\"train\":{}, \"test\":{}},\n",
    "               \"hist_features\":{\"train\":{}, \"test\":{}},\n",
    "               \"crbm_features\":{\"train\":{}, \"test\":{}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_auc = {\"original_features\":{\"train\":{}, \"test\":{}},\n",
    "               \"hist_features\":{\"train\":{}, \"test\":{}},\n",
    "               \"crbm_features\":{\"train\":{}, \"test\":{}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Metrics used #########\n",
    "def accuracy(y, y_hat):\n",
    "    return  sum(y == y_hat)/float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define models to experiment with #########\n",
    "models = [(\"LogisticRegression\", sklearn.linear_model.LogisticRegression()),\n",
    "          (\"MLPClassifier\", sklearn.neural_network.MLPClassifier()),\n",
    "          (\"KNeighborsClassifier\",sklearn.neighbors.KNeighborsClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define the three data parts used #########\n",
    "data_splits = ((\"original_features\", X_tr, y_tr, X_te, y_te),\n",
    "               (\"hist_features\", X_tr_hist, y_tr, X_te_hist, y_te),\n",
    "               (\"crbm_features\", X_tr_crbm,y_tr_crbm, X_te_crbm, y_te_crbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### We can add a grid and make model=grid to do grid search #########\n",
    "grid_params = {\"LogisticRegression\":{ \"C\":[0.8, 0.9, 1, 1.1, 1.2] },\n",
    "                \"MLPClassifier\":{\"hidden_layer_sizes\":[(100,), (200,), (300,), (400,), (500,)]},\n",
    "                \"KNeighborsClassifier\":{\"n_neighbors\":[5, 10, 15]} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "###### Train the different models #########\n",
    "for modelname,current_model in models:\n",
    "    g_params = grid_params[modelname]\n",
    "    print(\"\\n\\n\\tMODEL:\", modelname)\n",
    "    \n",
    "    for dataname, Xtr, ytr, Xte, yte in data_splits:\n",
    "        print(\"\\n\\t\\tWorking with data: \", dataname, \" shape of Xtr\", Xtr.shape)\n",
    "        model = sklearn.model_selection.GridSearchCV(current_model, g_params, n_jobs=-1)\n",
    "        model.fit(Xtr, ytr)\n",
    "        \n",
    "        results_acc[dataname][\"train\"][modelname] = accuracy(model.predict(Xtr), ytr)\n",
    "        results_acc[dataname][\"test\"][modelname] = accuracy(model.predict(Xte), yte)\n",
    "        cv_results = pd.DataFrame(model.cv_results_)\n",
    "        cv_results.to_json('./resultsfinal/resultsfinal_cv_' + modelname + \"_\" + dataname +'.json')\n",
    "        print(\"\\t\\tBest model of the grid selected. Results in train and test saved\")\n",
    "\n",
    "        conf_mat_tr = confusion_matrix(ytr, model.predict(Xtr))\n",
    "        conf_mat_te = confusion_matrix(yte, model.predict(Xte))\n",
    "\n",
    "        pd.DataFrame(conf_mat_tr).to_csv('./resultsfinal/predictions/conf_mat_tr_' + modelname + \"_\" + dataname +'.json')\n",
    "        pd.DataFrame(conf_mat_te).to_csv('./resultsfinal/predictions/conf_mat_te_' + modelname + \"_\" + dataname +'.json')\n",
    "        print(\"\\t\\tConfusion Matrix saved\")\n",
    "\n",
    "        pd.DataFrame(model.predict(Xtr)).to_csv('./resultsfinal/predictions/y_tr_hat_' + modelname + \"_\" + dataname +'.json')\n",
    "        pd.DataFrame(model.predict(Xte)).to_csv('./resultsfinal/predictions/y_te_hat_' + modelname + \"_\" + dataname +'.json')\n",
    "        print(\"\\t\\tModel predictions saved\")\n",
    "        \n",
    "        auc_tr = sklearn.metrics.f1_score(ytr, model.predict(Xtr), average=\"weighted\")\n",
    "        auc_te = sklearn.metrics.f1_score(yte, model.predict(Xte), average=\"weighted\")\n",
    "        pd.DataFrame({\"train\": [auc_tr], \"test\": [auc_te]}).to_csv('./resultsfinal/predictions/f1_weighted' + modelname + \"_\" + dataname +'.json')\n",
    "        print(\"\\t\\tData saved for: \", dataname)\n",
    "        del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Train the different models #########\n",
    "final_results = pd.DataFrame(results_acc)\n",
    "final_results.to_json(\"./resultsfinal/all_results.json\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
